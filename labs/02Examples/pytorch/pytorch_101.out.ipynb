{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to PyTorch\n",
        "\n",
        "# Introduction to PyTorch\n",
        "\n",
        "Based on Bourkes’s https://www.learnpytorch.io/\n",
        "\n",
        "## 1. Tensors are everywhere\n",
        "\n",
        "Tensors are the fundamental building blocks of machine learning."
      ],
      "id": "10656cc4-ff86-4984-8463-fa11dc11dbb1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "id": "398dc2b2-a6a1-43e3-b803-d97b9b1489fd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start by creating basic tensors\n",
        "\n",
        "-   scalar\n",
        "-   vector\n",
        "-   matrix\n",
        "-   tensor\n",
        "\n",
        "Please see official doc at https://pytorch.org/docs/stable/tensors.html"
      ],
      "id": "20aacf3d-066c-47dd-9de0-95c63733f09a"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          }
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "id": "ae4d3b3a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0"
            ]
          }
        }
      ],
      "source": [
        "scalar.ndim"
      ],
      "id": "7b01e540"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To retrieve the value, use the `item` method"
      ],
      "id": "2942dae3-ccf0-4d26-9366-9600efc92dab"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "7"
            ]
          }
        }
      ],
      "source": [
        "scalar.item()"
      ],
      "id": "b8086924"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          }
        }
      ],
      "source": [
        "# vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "id": "9eacf829"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "1"
            ]
          }
        }
      ],
      "source": [
        "vector.ndim"
      ],
      "id": "36e7a505"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          }
        }
      ],
      "source": [
        "vector.shape"
      ],
      "id": "9e1f9357"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   `ndim` gives the number of external square brackets\n",
        "-   `shape` gives the actual dimension = length"
      ],
      "id": "7aa6055a-0f9a-49fd-bcb4-7528fc428939"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          }
        }
      ],
      "source": [
        "# matrix\n",
        "MAT = torch.tensor([[7, 8], [9, 10]])\n",
        "MAT"
      ],
      "id": "7bc4d5aa"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "2"
            ]
          }
        }
      ],
      "source": [
        "MAT.ndim"
      ],
      "id": "b210caaf"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          }
        }
      ],
      "source": [
        "MAT.shape"
      ],
      "id": "e5711b71"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          }
        }
      ],
      "source": [
        "# tensor\n",
        "TEN = torch.tensor([[[1, 2, 3],\n",
        "         [3, 6, 9],\n",
        "         [2, 4, 5]]])\n",
        "TEN"
      ],
      "id": "fb9296ae"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          }
        }
      ],
      "source": [
        "TEN.shape"
      ],
      "id": "b32b79bb"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "3"
            ]
          }
        }
      ],
      "source": [
        "TEN.ndim"
      ],
      "id": "073bc1a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dimensions of a tensor go from outer to inner. That means there’s 1\n",
        "dimension of 3 by 3.\n",
        "\n",
        "![](attachment:./00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "## Random-valued Tensors\n",
        "\n",
        "Tensors of *random numbers* are very common in ML. They are used\n",
        "evrywhere."
      ],
      "attachments": {
        "./00-pytorch-different-tensor-dimensions.png": {
          "image/png": "\n"
        }
      },
      "id": "cd20d44e-582c-4f6c-b443-f16eda7dfda5"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[0.2350, 0.7880, 0.7052, 0.5025],\n",
              "         [0.5523, 0.6008, 0.9949, 0.4443],\n",
              "         [0.5769, 0.7505, 0.1360, 0.8363]]),\n",
              " torch.float32)"
            ]
          }
        }
      ],
      "source": [
        "rand_tensor = torch.rand(size=(3, 4))\n",
        "rand_tensor, rand_tensor.dtype"
      ],
      "id": "723b98f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other special tensors"
      ],
      "id": "653d1418-0134-47b3-937f-24dce025cc98"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          }
        }
      ],
      "source": [
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ],
      "id": "391204bd"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          }
        }
      ],
      "source": [
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype"
      ],
      "id": "f312a1a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a range of numbers in a tensor.\n",
        "\n",
        "`torch.arange(start, end, step)`"
      ],
      "id": "07ce90fc-47a6-4225-bb78-0315066f15ba"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          }
        }
      ],
      "source": [
        "zero_to_ten = torch.arange(0,10)\n",
        "zero_to_ten"
      ],
      "id": "b91331a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a tensor of the same shape as another.\n",
        "\n",
        "`torch.zeros_like(input)`"
      ],
      "id": "51e9eb10-7122-4805-9518-f9dd771f71dc"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          }
        }
      ],
      "source": [
        "ten_zeros = torch.zeros_like(zero_to_ten)\n",
        "ten_zeros"
      ],
      "id": "6dc0c1a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor datatypes\n",
        "\n",
        "Many datatypes are available, some specific for CPUs, others better for\n",
        "GPUs.\n",
        "\n",
        "Default datatype is a `float32`, defined by `torch.float32()` or just\n",
        "`torch.float()`.\n",
        "\n",
        "Lower precision values are faster to compute with, but less acccurate…"
      ],
      "id": "04d89ca0-64af-4134-a415-4524c01dc829"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          }
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "id": "9f2b039b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us place a tensor on the GPU (usually “cuda”, bit here it is “mps”\n",
        "for a Mac)"
      ],
      "id": "dfb1e8fc-ca82-4fc0-b7b0-9e48850b6aa2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='mps', index=0))"
            ]
          }
        }
      ],
      "source": [
        "# Default datatype for tensors is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=\"mps\", # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "id": "07ac9f87"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most common issues for mismatch are:\n",
        "\n",
        "-   shape differences\n",
        "-   datatype\n",
        "-   device issues"
      ],
      "id": "0535d920-a950-4030-a2bd-cb3275aba26c"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          }
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ],
      "id": "c1cc7c7c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get info from tensors\n",
        "\n",
        "This is often necessary to ensure compatibility and to avoid pesky bugs."
      ],
      "id": "89f3837b-d746-4a5d-8b67-99b9c713f3c2"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7783, 0.1803, 0.1316, 0.2174],\n",
            "        [0.5707, 0.7213, 0.5195, 0.5730],\n",
            "        [0.6286, 0.9001, 0.8025, 0.5707]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Find out details about it\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
      ],
      "id": "11edb2e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor operations\n",
        "\n",
        "-   Basic operations\n",
        "-   Matrix multiplication\n",
        "-   Aggregation (min, max, mean, etc.)\n",
        "-   Reshaping, squeezing"
      ],
      "id": "3b260708-39c9-4e3e-9e49-5a3463ad09d5"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          }
        }
      ],
      "source": [
        "# Create a tensor of values and add a number to it\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ],
      "id": "46b22cf7"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          }
        }
      ],
      "source": [
        "# Multiply it by 10\n",
        "tensor * 10"
      ],
      "id": "d65be04b"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tm =  tensor([10, 20, 30])\n",
            "ta =  tensor([11, 12, 13])"
          ]
        }
      ],
      "source": [
        "# Can also use torch functions\n",
        "tm = torch.mul(tensor, 10)\n",
        "ta = torch.add(tensor, 10)\n",
        "\n",
        "print(\"tm = \", tm)\n",
        "print(\"ta = \", ta)"
      ],
      "id": "cf89f37b"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication \n",
        "# (each element multiplies its equivalent, index 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)"
      ],
      "id": "9764ad09"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          }
        }
      ],
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "# Element-wise matrix multiplication\n",
        "tensor * tensor"
      ],
      "id": "1075e5bd"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          }
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ],
      "id": "5863d9cb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Built-in `torch.matmul()` is much faster and should always be used."
      ],
      "id": "06f4668b-0caf-4289-99df-c5f329051a5c"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.16 ms, sys: 738 µs, total: 1.89 ms\n",
            "Wall time: 1.31 ms"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          }
        }
      ],
      "source": [
        "%%time\n",
        "# Matrix multiplication by hand \n",
        "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value"
      ],
      "id": "768f3908"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 310 µs, sys: 85 µs, total: 395 µs\n",
            "Wall time: 368 µs"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          }
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "id": "ce679889"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, shapes must be compatible for matrix multiplication…"
      ],
      "id": "878b2b34-696f-424b-b2bf-be1279937349"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shapes need to be in the right way  \n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11], \n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "id": "b0d45333"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.,  9.],\n",
            "        [10., 11., 12.]])"
          ]
        }
      ],
      "source": [
        "# View tensor_A and tensor_B.T\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)"
      ],
      "id": "4a810eaa"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])"
          ]
        }
      ],
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output) \n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "id": "3384149c"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.,  33.],\n",
              "        [ 61.,  68.,  75.],\n",
              "        [ 95., 106., 117.]])"
            ]
          }
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B.T)"
      ],
      "id": "3961f209"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensor multiplication: example of linear regression\n",
        "\n",
        "Neural networks are full of matrix multiplications and dot products.\n",
        "\n",
        "The `torch.nn.Linear()` module (that we will see in the next pytorch\n",
        "tutorial), also known as a feed-forward layer or fully connected layer,\n",
        "implements a matrix multiplication between an input $x$ and a weights\n",
        "matrix $A.$\n",
        "\n",
        "$$ y = x A^T + b, $$\n",
        "\n",
        "where\n",
        "\n",
        "-   $x$ is the input to the layer (deep learning is a stack of layers\n",
        "    like torch.nn.Linear() and others on top of each other).\n",
        "-   $A$ is the weights matrix created by the layer, this starts out as\n",
        "    random numbers that get adjusted as a neural network learns to\n",
        "    better represent patterns in the data (notice the “T”, that’s\n",
        "    because the weights matrix gets transposed). Note: You might also\n",
        "    often see $W$ or another letter like $X$ used to denote the weights\n",
        "    matrix.\n",
        "-   $b$ is the bias term used to slightly offset the weights and inputs.\n",
        "-   $y$ is the output (a manipulation of the input in the hope to\n",
        "    discover patterns in it).\n",
        "\n",
        "This is just a linear function, of type $y = ax+b,$ that can be used to\n",
        "draw a straight line."
      ],
      "id": "cacb7cc2-6425-4db5-a4cb-17003398a3e2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])"
          ]
        }
      ],
      "source": [
        "# Since the linear layer starts with a random weights matrix, we make it reproducible (more on this later)\n",
        "torch.manual_seed(42)\n",
        "# This uses matrix multiplication\n",
        "linear = torch.nn.Linear(in_features=2,  # in_features = matches inner dimension of input \n",
        "                         out_features=6) # out_features = describes outer value \n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
      ],
      "id": "e0cd9703"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aggregation Functions\n",
        "\n",
        "Now for some aggregation functions."
      ],
      "id": "49ef57c5-a272-42fa-8a9b-37a79cebd054"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          }
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ],
      "id": "f5896e22"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # this will error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
        "print(f\"Sum: {x.sum()}\")"
      ],
      "id": "b40af284"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          }
        }
      ],
      "source": [
        "# alternative: use torch methods\n",
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ],
      "id": "b28b5318"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Positional min/max functions are\n",
        "\n",
        "-   `torch.argmin()`\n",
        "-   `torch.argmax()`"
      ],
      "id": "525f860b-a4b7-4c37-85ae-d45df67f3149"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0"
          ]
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Returns index of max and min values\n",
        "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tensor.argmin()}\")"
      ],
      "id": "2f9548a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Changing datatype is possible (recasting)"
      ],
      "id": "09b6c1ad-8468-4a4f-9f2d-f062c408b600"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          }
        }
      ],
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "id": "e49633fb"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          }
        }
      ],
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ],
      "id": "1db05834"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          }
        }
      ],
      "source": [
        "# Create a int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ],
      "id": "ba16e2a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reshaping, stacking, squeezing of tensors\n",
        "\n",
        "-   `torch.reshape(input, shape)`\n",
        "-   `torch.Tensor.view(shape)` to obtain a view\n",
        "-   `torch.stack(tensors, dim=0)` to concatenate along a given direction\n",
        "-   `torch.squeeze(input)` to remove all dimensions of value `1`\n",
        "-   `torch.unsqueeze(input, dim)` to add a dimension of value `1` at\n",
        "    `dim`\n",
        "-   `torch.permute(input, dims)` to permute to `dims`"
      ],
      "id": "8ecec205-869c-4cc4-bea6-fe207e3a5968"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          }
        }
      ],
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape"
      ],
      "id": "12499e76"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          }
        }
      ],
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "id": "68385f8e"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          }
        }
      ],
      "source": [
        "# Change view (keeps same data as original but changes view)\n",
        "z = x.view(1, 7)\n",
        "z, z.shape"
      ],
      "id": "a70b25fe"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          }
        }
      ],
      "source": [
        "# Changing z changes x\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "id": "a32217a1"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          }
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ],
      "id": "cac79e7f"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.]])"
            ]
          }
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=1) # try changing dim to dim=1 and see what happens\n",
        "x_stacked"
      ],
      "id": "e6211be3"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "id": "5d603371"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])"
          ]
        }
      ],
      "source": [
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "id": "6cebe46d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Slicing\n",
        "\n",
        "Often we need to extract subsets of data from tensors, usually, some\n",
        "rows or columns.\n",
        "\n",
        "Let’s look at indexing."
      ],
      "id": "b7c44849-614d-43f6-ae27-108187258fc6"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          }
        }
      ],
      "source": [
        "# Create a tensor \n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ],
      "id": "cd6d552a"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1"
          ]
        }
      ],
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\") \n",
        "print(f\"Second square bracket: {x[0][0]}\") \n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ],
      "id": "bfbf64b5"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          }
        }
      ],
      "source": [
        "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ],
      "id": "b032aeb4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### PyTorch tensors and NumPy\n",
        "\n",
        "We often need to interact with `numpy`, especially for numerical\n",
        "computations.\n",
        "\n",
        "The two main methods are:\n",
        "\n",
        "-   `torch.from_numpy(ndarray)`\n",
        "-   `torch.Tensor.numpy()`"
      ],
      "id": "4d14a049-8e5e-4688-9eb2-7108ab3e68d7"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          }
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ],
      "id": "6715c45d"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
            ]
          }
        }
      ],
      "source": [
        "# many pytorch calculations require 'float32'\n",
        "tensor32 = torch.from_numpy(array).type(torch.float32)\n",
        "tensor32, tensor32.dtype"
      ],
      "id": "4ac43fba"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          }
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "id": "e40b4196"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reproducibility\n",
        "\n",
        "To ensure reproducibility of computations, especially ML training, we\n",
        "need to set the random seed."
      ],
      "id": "978ddd12-fe94-4faf-95e2-b64cff8963e4"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "#import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
        "torch.manual_seed(seed=RANDOM_SEED) \n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called \n",
        "# Without this, tensor_D would be different to tensor_C \n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_tensor_C == random_tensor_D"
      ],
      "id": "a63cf1a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Running computations on the GPU\n",
        "\n",
        "See also the code in `pytorch_M2.ipynb`.\n",
        "\n",
        "Usually the command sequence is:\n",
        "\n",
        "``` python\n",
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "```"
      ],
      "id": "5f198c47-04b0-47d0-a3a2-e3a3891db54c"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "'mps'"
            ]
          }
        }
      ],
      "source": [
        "# check for gpu on mac\n",
        "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "device"
      ],
      "id": "13878d2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To put tensors on the GPU, just use the method `tensor.to(device)`, or\n",
        "put the device option directly into the tensor initialization as seen\n",
        "above:\n",
        "\n",
        "``` python\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,  \n",
        "                               device=\"mps\",  \n",
        "                               requires_grad=False)  \n",
        "```"
      ],
      "id": "9ee8c0bf-aa17-4dab-8d6f-d51ceec8e37d"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          }
        }
      ],
      "source": [
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "id": "487916bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you need to interact with your tensors (numpy, matplotlib, etc.),\n",
        "then need to get them back to the CPU. Here we use the method\n",
        "`Tensor.cpu()`"
      ],
      "id": "2fb11257-fd78-414c-841b-65657cd7f824"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()"
      ],
      "id": "f21b1d05"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          }
        }
      ],
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "id": "85eec088"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          }
        }
      ],
      "source": [
        "# original is still on the GPU\n",
        "tensor_on_gpu"
      ],
      "id": "859bec50"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  }
}