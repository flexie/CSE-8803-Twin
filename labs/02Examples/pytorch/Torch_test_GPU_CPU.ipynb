{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9339e5-2fb5-4f00-8ced-06fbcb3ecdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# check availability of GPU\n",
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52623950-4d88-46b7-aa6e-4bf3f4764fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0122362919998977"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example on GPU\n",
    "import timeit\n",
    "import torch\n",
    "import random\n",
    "\n",
    "x = torch.ones(5000, device=\"mps\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=100000)\n",
    "#Out[17]: 4.568202124999971\n",
    "\n",
    "# toy example cpu\n",
    "#x = torch.ones(5000, device=\"cpu\")\n",
    "# timeit.timeit(lambda: x * random.randint(0,100), number=100000)\n",
    "#Out[18]: 0.30446054200001527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ba319a-6e9b-47fd-a2b2-2424d4039f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24692429099991386"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example on cpu\n",
    "x = torch.ones(5000, device=\"cpu\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a836f8c",
   "metadata": {},
   "source": [
    "The CPU is approximately 10 times faster than the GPU...\n",
    "\n",
    "Here is a slightly more complex examples, with a matrix-vector tensor multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0caaa8f-b5d0-4b2b-a9c3-325e907c8c84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 0.8405147910000323\n",
      "mps 2.3573820419999265\n"
     ]
    }
   ],
   "source": [
    "a_cpu = torch.rand(250, device='cpu')\n",
    "b_cpu = torch.rand((250, 250), device='cpu')\n",
    "a_mps = torch.rand(250, device='mps')\n",
    "b_mps = torch.rand((250, 250), device='mps')\n",
    "\n",
    "print('cpu', timeit.timeit(lambda: a_cpu @ b_cpu, number=100_000))\n",
    "print('mps', timeit.timeit(lambda: a_mps @ b_mps, number=100_000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f282f5",
   "metadata": {},
   "source": [
    "Now, we drastically increase the problem size, using the tensor dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da31b9a2-bfcb-4845-9da2-7f09b369a49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048149999997804116"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device=\"mps\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04fe6d3d-7bf4-4403-aab0-428c82675b6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03234533299996656"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(50000000, device=\"cpu\")\n",
    "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1748208e-930c-4d66-9890-e3729567e2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.29166666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".0323/.00048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2124a72-71dc-4660-a455-c49075832623",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "GPU works well, but only for LARGE memory problems. This is because loading small data to memory and using GPU for calculation is overkill, so the CPU has an advantage in this case. But if you have large data dimensions, the GPU can compute  efficiently and surpass the CPU.\n",
    "\n",
    "This is well known with GPUs: they are only faster if you put a large computational load. It is not specific to pytorch or to MPS..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051c7a2-cf57-462a-8ed4-a23319324fea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
