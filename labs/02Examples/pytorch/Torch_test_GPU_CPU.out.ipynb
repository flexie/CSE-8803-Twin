{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#"
      ],
      "id": "c0e44ddf-831f-4f90-b71d-453338d413cf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.], device='mps:0')"
          ]
        }
      ],
      "source": [
        "# check availability of GPU\n",
        "import torch\n",
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ],
      "id": "db9339e5-2fb5-4f00-8ced-06fbcb3ecdd2"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "2.0122362919998977"
            ]
          }
        }
      ],
      "source": [
        "# toy example on GPU\n",
        "import timeit\n",
        "import torch\n",
        "import random\n",
        "\n",
        "x = torch.ones(5000, device=\"mps\")\n",
        "timeit.timeit(lambda: x * random.randint(0,100), number=100000)\n",
        "#Out[17]: 4.568202124999971\n",
        "\n",
        "# toy example cpu\n",
        "#x = torch.ones(5000, device=\"cpu\")\n",
        "# timeit.timeit(lambda: x * random.randint(0,100), number=100000)\n",
        "#Out[18]: 0.30446054200001527"
      ],
      "id": "52623950-4d88-46b7-aa6e-4bf3f4764fdd"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0.24692429099991386"
            ]
          }
        }
      ],
      "source": [
        "# toy example on cpu\n",
        "x = torch.ones(5000, device=\"cpu\")\n",
        "timeit.timeit(lambda: x * random.randint(0,100), number=100000)"
      ],
      "id": "63ba319a-6e9b-47fd-a2b2-2424d4039f77"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CPU is approximately 10 times faster than the GPU…\n",
        "\n",
        "Here is a slightly more complex examples, with a matrix-vector tensor\n",
        "multiplication."
      ],
      "id": "b85de22d-555f-408d-9d01-f46c77da7a28"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu 0.8405147910000323\n",
            "mps 2.3573820419999265"
          ]
        }
      ],
      "source": [
        "a_cpu = torch.rand(250, device='cpu')\n",
        "b_cpu = torch.rand((250, 250), device='cpu')\n",
        "a_mps = torch.rand(250, device='mps')\n",
        "b_mps = torch.rand((250, 250), device='mps')\n",
        "\n",
        "print('cpu', timeit.timeit(lambda: a_cpu @ b_cpu, number=100_000))\n",
        "print('mps', timeit.timeit(lambda: a_mps @ b_mps, number=100_000))"
      ],
      "id": "d0caaa8f-b5d0-4b2b-a9c3-325e907c8c84"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we drastically increase the problem size, using the tensor\n",
        "dimension."
      ],
      "id": "fbc771f0-3506-4f1a-8d3c-74b421fd2089"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0.00048149999997804116"
            ]
          }
        }
      ],
      "source": [
        "x = torch.ones(50000000, device=\"mps\")\n",
        "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
      ],
      "id": "da31b9a2-bfcb-4845-9da2-7f09b369a49f"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "0.03234533299996656"
            ]
          }
        }
      ],
      "source": [
        "x = torch.ones(50000000, device=\"cpu\")\n",
        "timeit.timeit(lambda: x * random.randint(0,100), number=1)"
      ],
      "id": "04fe6d3d-7bf4-4403-aab0-428c82675b6a"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "67.29166666666667"
            ]
          }
        }
      ],
      "source": [
        ".0323/.00048"
      ],
      "id": "1748208e-930c-4d66-9890-e3729567e2f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "GPU works well, but only for LARGE memory problems. This is because\n",
        "loading small data to memory and using GPU for calculation is overkill,\n",
        "so the CPU has an advantage in this case. But if you have large data\n",
        "dimensions, the GPU can compute efficiently and surpass the CPU.\n",
        "\n",
        "This is well known with GPUs: they are only faster if you put a large\n",
        "computational load. It is not specific to pytorch or to MPS…"
      ],
      "id": "d34f18b3-7bb5-4303-a9e7-b6ee0bfafe63"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  }
}